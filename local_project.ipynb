{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Test comptage de mot\n",
    "\n",
    "- Test actuellement KO. Essayer de suivre [ce tuto](https://www.knowledgehut.com/blog/big-data/install-spark-on-ubuntu) avec version antierieure pour etre sur que cela peut fonctionner."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPARK_HOME : /opt/spark-3.2.4-bin-hadoop2.7\n",
      "JAVA_HOME :  /opt/jdk/jdk1.8.0_202\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"SPARK_HOME :\", os.environ['SPARK_HOME'])\n",
    "print(\"JAVA_HOME : \", os.environ['JAVA_HOME'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-19T17:44:03.842532Z",
     "end_time": "2023-07-19T17:44:03.845107Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/19 17:44:07 WARN Utils: Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.1.15 instead (on interface wlp0s20f3)\n",
      "23/07/19 17:44:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/19 17:44:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "[Stage 0:>                                                          (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pyroman 1\n",
      "voulu 3\n",
      "Tony 3\n",
      "dans 17\n",
      "rue 3\n",
      "l'addition 3\n",
      "est 13\n",
      "salée 3\n",
      "salée) 3\n",
      "pas 12\n",
      "les 10\n",
      "feras 3\n",
      "cadet 3\n",
      "J'ai 8\n",
      "grandi 3\n",
      "au 8\n",
      "jamais 3\n",
      "chatte 3\n",
      "mon 4\n",
      "lit 3\n",
      "sent 3\n",
      "le 12\n",
      "poisson 3\n",
      "salé 3\n",
      "du 7\n",
      "cul) 3\n",
      "jusqu'à 4\n",
      "d'heure 4\n",
      "(Traînait, 3\n",
      "traînait) 3\n",
      "que 4\n",
      "connais 4\n",
      "mes 5\n",
      "ennemis 4\n",
      "d'la 4\n",
      "perdu) 3\n",
      "Torse 4\n",
      "comme 8\n",
      "mongole, 4\n",
      "insultait 4\n",
      "passants 4\n",
      "passaient 4\n",
      "Le 4\n",
      "pendant 4\n",
      "nuit, 4\n",
      "Seigneur 4\n",
      "brr) 3\n",
      "Mais 1\n",
      "ça, 1\n",
      "personne 1\n",
      "parle 1\n",
      "? 3\n",
      "(Huh) 2\n",
      "Quand 1\n",
      "est-ce 1\n",
      "va 1\n",
      "manger 1\n",
      "Certains 1\n",
      "d'entre 1\n",
      "eux 1\n",
      "nous 2\n",
      "voir 1\n",
      "(Nan), 1\n",
      "m'raconte 1\n",
      "tes 1\n",
      "salades, 1\n",
      "ce 1\n",
      "soir, 1\n",
      "j'vais 1\n",
      "mayo 1\n",
      "dealé 1\n",
      "coin, 1\n",
      "déployé 1\n",
      "charo 1\n",
      "like 1\n",
      "Candy 1\n",
      "Necklace 1\n",
      "Del 1\n",
      "Escorte 1\n",
      "Werenoi 1\n",
      "Ils 1\n",
      "dit 1\n",
      "\"Demain, 1\n",
      "n'y 1\n",
      "croit 1\n",
      "même 1\n",
      "j'suis 1\n",
      "mer, 1\n",
      "j'allume 1\n",
      "Cohiba 1\n",
      "bye, 1\n",
      "bye) 1\n",
      "des 3\n",
      "PIB 1\n",
      "fait 1\n",
      "bails 1\n",
      "j'baise 1\n",
      "prohibés, 1\n",
      "taf, 1\n",
      "ça 1\n",
      "paie 1\n",
      "(Jamain) 1\n",
      "Igo, 1\n",
      "donne-moi 2\n",
      "maille, 1\n",
      "ou 1\n",
      "j'brise 1\n",
      "vitre 1\n",
      "Elle 1\n",
      "veut 1\n",
      "s'acheter 1\n",
      "fringues, 1\n",
      "elle 1\n",
      "bosse 1\n",
      "pour 1\n",
      "sur 1\n",
      "sert 1\n",
      "jouer 1\n",
      "viendra 1\n",
      "faire 1\n",
      "coup 1\n",
      "d'fil, 1\n",
      "d'faire 1\n",
      "enlever 1\n",
      "Khey 2\n",
      "attitude, 2\n",
      "tient 2\n",
      "rênes 2\n",
      "nôtres) 1\n",
      "T'as 3\n",
      "la 23\n",
      "vie 4\n",
      "de 14\n",
      "mais 4\n",
      "(L'addition 3\n",
      "Ne 3\n",
      "joue 3\n",
      "gros 3\n",
      "street, 5\n",
      "tu 4\n",
      "te 5\n",
      "monter 3\n",
      "par 3\n",
      "un 9\n",
      "l'illégal, 3\n",
      "'phone, 3\n",
      "il 3\n",
      "ne 4\n",
      "faut 3\n",
      "parler 3\n",
      "La 3\n",
      "petite 3\n",
      "sale, 3\n",
      "(Pue 3\n",
      "baigné 4\n",
      "Champtier 4\n",
      "Coq, 4\n",
      "on 12\n",
      "trainait 4\n",
      "dehors 4\n",
      "Depuis 4\n",
      "je 4\n",
      "Glock, 4\n",
      "ont 5\n",
      "perdu 4\n",
      "valeur 4\n",
      "(Tout 3\n",
      "nu 4\n",
      "qui 4\n",
      "(Fils 3\n",
      "pute) 3\n",
      "ciel 4\n",
      "gronde 4\n",
      "l'impression 4\n",
      "qu'le 4\n",
      "fâché 4\n",
      "(Brr, 3\n",
      "comment 1\n",
      "qu'on 1\n",
      "notre 1\n",
      "part 1\n",
      "veulent 2\n",
      "m'traite 1\n",
      "putain 1\n",
      "d'esclave 1\n",
      "Ma 1\n",
      "chérie, 1\n",
      "verser 1\n",
      "(Du 1\n",
      "me-sper) 1\n",
      "ma 1\n",
      "dope 1\n",
      "j'ai 2\n",
      "ailes 1\n",
      "You 1\n",
      "might 1\n",
      "also 1\n",
      "Lana 1\n",
      "Rey 1\n",
      "Freeze 2\n",
      "Raël 1\n",
      "Corleone 1\n",
      ": 1\n",
      "c'est 1\n",
      "loin\" 1\n",
      "J'vous 1\n",
      "emmerde, 1\n",
      "bord 1\n",
      "(Bye, 1\n",
      "J'reviens 1\n",
      "Pays-Bas, 1\n",
      "j'augmente 1\n",
      "On 2\n",
      "et 3\n",
      "l'bail 1\n",
      "nouvelles 1\n",
      "VivaStreet 1\n",
      "À 1\n",
      "quoi 2\n",
      "bon 1\n",
      "dingues 1\n",
      "où 1\n",
      "habites 1\n",
      "Un 1\n",
      "une 1\n",
      "liasse 1\n",
      "l'enveloppe, 1\n",
      "N.W.A 2\n",
      "Deep 2\n",
      "(Ils 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "# Instantiation d'un SparkContext\n",
    "sc = SparkContext()\n",
    "\n",
    "# Lecture d'un fichier texte : le fichier est décomposé en lignes.\n",
    "lines = sc.textFile(\"./example/text.txt\")\n",
    "\n",
    "# Décomposition de chaque ligne en mots\n",
    "word_counts = (lines.flatMap(lambda line: line.split(' '))\n",
    "                   # Chacun des mots est transformé en une clé-valeur\n",
    "                   .map(lambda mot: (mot, 1))\n",
    "                   # Les valeurs associées à chaques clé sont sommées\n",
    "                   .reduceByKey(lambda count1, count2: count1 + count2)\n",
    "                   # Le résultat est récupéré\n",
    "                   .collect())\n",
    "\n",
    "# Chaque paire (clé, valeur) est affichée\n",
    "for (word, count) in word_counts:\n",
    "    print(word, count)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-19T17:44:06.037372Z",
     "end_time": "2023-07-19T17:44:11.108758Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Déploiement de la solution en local\n",
    "\n",
    "\n",
    "## 3.1 Environnement de travail\n",
    "\n",
    "Pour des raisons de simplicité, nous développons dans un environnement <br />\n",
    "Linux Unbuntu (exécuté depuis une machine Windows dans une machine virtuelle)\n",
    "* Pour installer une machine virtuelle :  https://www.malekal.com/meilleurs-logiciels-de-machine-virtuelle-gratuits-ou-payants/\n",
    "\n",
    "## 3.2 Installation de Spark\n",
    "\n",
    "[La première étape consiste à installer Spark ](https://computingforgeeks.com/how-to-install-apache-spark-on-ubuntu-debian/)\n",
    "\n",
    "## 3.3 Installation des packages\n",
    "\n",
    "<u>On installe ensuite à l'aide de la commande **pip** <br />\n",
    "les packages qui nous seront nécessaires</u> :"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "728d9256",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2023-07-19T17:44:33.872785Z",
     "end_time": "2023-07-19T17:44:35.725763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pandas in /home/maximorose/.local/lib/python3.10/site-packages (1.5.3)\r\n",
      "Requirement already satisfied: pillow in /home/maximorose/.local/lib/python3.10/site-packages (9.4.0)\r\n",
      "Requirement already satisfied: tensorflow in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (2.10.0)\r\n",
      "Requirement already satisfied: pyspark in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (3.2.1)\r\n",
      "Requirement already satisfied: pyarrow in /home/maximorose/.local/lib/python3.10/site-packages (11.0.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/maximorose/.local/lib/python3.10/site-packages (from Pandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from Pandas) (2022.7)\r\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/maximorose/.local/lib/python3.10/site-packages (from Pandas) (1.24.1)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorflow) (1.3.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorflow) (2.0)\r\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorflow) (0.4.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorflow) (3.7.0)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorflow) (1.1.2)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorflow) (16.0.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorflow) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /home/maximorose/.local/lib/python3.10/site-packages (from tensorflow) (23.0)\r\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorflow) (3.19.6)\r\n",
      "Requirement already satisfied: setuptools in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorflow) (67.8.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorflow) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorflow) (2.1.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/maximorose/.local/lib/python3.10/site-packages (from tensorflow) (4.5.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorflow) (1.14.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorflow) (0.32.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorflow) (1.42.0)\r\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorflow) (2.10.0)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorflow) (2.10.0)\r\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorflow) (2.10.0)\r\n",
      "Requirement already satisfied: py4j==0.10.9.3 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from pyspark) (0.10.9.3)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.6.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.4)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/maximorose/.local/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/maximorose/.local/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.2)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/maximorose/.local/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.3.4)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/maximorose/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.3.1)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/maximorose/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.7.2)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/maximorose/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.0.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/maximorose/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2023.5.7)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/maximorose/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.2)\r\n",
      "Collecting pyasn1<0.5.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow)\r\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.1)\r\n",
      "Installing collected packages: pyasn1\r\n",
      "  Attempting uninstall: pyasn1\r\n",
      "    Found existing installation: pyasn1 0.5.0\r\n",
      "    Uninstalling pyasn1-0.5.0:\r\n",
      "      Successfully uninstalled pyasn1-0.5.0\r\n",
      "Successfully installed pyasn1-0.4.8\r\n"
     ]
    }
   ],
   "source": [
    "!pip install Pandas pillow tensorflow pyspark pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a43845",
   "metadata": {},
   "source": [
    "## 3.4 Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5c0c74f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-19T17:44:38.311510Z",
     "end_time": "2023-07-19T17:44:40.522509Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 17:44:38.738062: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras import Model\n",
    "from pyspark.sql.functions import col, pandas_udf, PandasUDFType, element_at, split\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# import findspark\n",
    "# findspark.init()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-19T17:44:54.125719Z",
     "end_time": "2023-07-19T17:44:54.135325Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "661ff67c",
   "metadata": {},
   "source": [
    "## 3.5 Définition des PATH pour charger les images <br /> et enregistrer les résultats\n",
    "\n",
    "Dans cette version locale nous partons du principe que les données <br />\n",
    "sont stockées dans le même répertoire que le notebook.<br />\n",
    "Nous n'utilisons qu'un extrait de **300 images** à traiter dans cette <br />\n",
    "première version en local.<br />\n",
    "L'extrait des images à charger est stockée dans le dossier **Test1**.<br />\n",
    "Nous enregistrerons le résultat de notre traitement <br />\n",
    "dans le dossier \"**Results_Local**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cde0aa67",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-19T17:44:56.619437Z",
     "end_time": "2023-07-19T17:44:56.630845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH:        /home/maximorose/git_repositories/oc-ds-p08\n",
      "PATH_Data:   /home/maximorose/git_repositories/oc-ds-p08/data/imgs\n",
      "PATH_Result: /home/maximorose/git_repositories/oc-ds-p08/results\n"
     ]
    }
   ],
   "source": [
    "PATH = os.getcwd()\n",
    "# PATH_Data = PATH+'/data/Test1'\n",
    "# PATH_Result = PATH+'/data/Results'\n",
    "PATH_Data = PATH+'/data/imgs'\n",
    "PATH_Result = PATH+'/results'\n",
    "print('PATH:        '+\\\n",
    "      PATH+'\\nPATH_Data:   '+\\\n",
    "      PATH_Data+'\\nPATH_Result: '+PATH_Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5e637a",
   "metadata": {},
   "source": [
    "## 3.6 Création de la SparkSession\n",
    "\n",
    "L’application Spark est contrôlée grâce à un processus de pilotage (driver process) appelé **SparkSession**. <br />\n",
    "<u>Une instance de **SparkSession** est la façon dont Spark exécute les fonctions définies par l’utilisateur <br />\n",
    "dans l’ensemble du cluster</u>. <u>Une SparkSession correspond toujours à une application Spark</u>.\n",
    "\n",
    "<u>Ici nous créons une session spark en spécifiant dans l'ordre</u> :\n",
    " 1. un **nom pour l'application**, qui sera affichée dans l'interface utilisateur Web Spark \"**P8**\"\n",
    " 2. que l'application doit s'exécuter **localement**. <br />\n",
    "   Nous ne définissons pas le nombre de cœurs à utiliser (comme .master('local[4]) pour 4 cœurs à utiliser), <br />\n",
    "   nous utiliserons donc tous les cœurs disponibles dans notre processeur.<br />\n",
    " 3. une option de configuration supplémentaire permettant d'utiliser le **format \"parquet\"** <br />\n",
    "   que nous utiliserons pour enregistrer et charger le résultat de notre travail.\n",
    " 4. vouloir **obtenir une session spark** existante ou si aucune n'existe, en créer une nouvelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7bea157",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-19T17:44:59.337136Z",
     "end_time": "2023-07-19T17:44:59.869018Z"
    }
   },
   "outputs": [],
   "source": [
    "# Probleme : https://stackoverflow.com/questions/69763427/pyspark-not-initialized/71855571#71855571\n",
    "# Parametre originaux : \"spark.sql.parquet.writeLegacyFormat\", 'true'\n",
    "# Test config : .config(\"spark.driver.host\", 'localhost')\n",
    "\n",
    "spark = (SparkSession\n",
    "             .builder\n",
    "             .appName('P8')\n",
    "             .master('local')\n",
    "             .config(\"spark.sql.parquet.writeLegacyFormat\", 'true')\n",
    "             .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8b53ac",
   "metadata": {},
   "source": [
    "<u>Nous créons également la variable \"**sc**\" qui est un **SparkContext** issue de la variable **spark**</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14aeccb1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-19T17:45:02.373286Z",
     "end_time": "2023-07-19T17:45:02.384138Z"
    }
   },
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a086010",
   "metadata": {},
   "source": [
    "<u>Affichage des informations de Spark en cours d'execution</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e97bf13b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-19T17:45:04.820500Z",
     "end_time": "2023-07-19T17:45:04.866029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0x7fd2efffad70>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://pop-os.home:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.2.4</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>pyspark-shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# SparkSession.builder.appName(\"test\").config(\n",
    "#     \"spark.driver.extraJavaOptions\",\n",
    "#     \"--add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED\",\n",
    "# ).getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-19T17:45:09.394211Z",
     "end_time": "2023-07-19T17:45:09.403511Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PySpark 3.2.4 version is running...\n"
     ]
    }
   ],
   "source": [
    "print(f'The PySpark {spark.version} version is running...')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-19T17:45:12.691220Z",
     "end_time": "2023-07-19T17:45:12.701531Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "195a88b0",
   "metadata": {},
   "source": [
    "## 3.7 Traitement des données\n",
    "\n",
    "<u>Dans la suite de notre flux de travail, <br />\n",
    "nous allons successivement</u> :\n",
    "1. Préparer nos données\n",
    "    1. Importer les images dans un dataframe **pandas UDF**\n",
    "    2. Associer aux images leur **label**\n",
    "    3. Préprocesser en **redimensionnant nos images pour <br />\n",
    "       qu'elles soient compatibles avec notre modèle**\n",
    "2. Préparer notre modèle\n",
    "    1. Importer le modèle **MobileNetV2**\n",
    "    2. Créer un **nouveau modèle** dépourvu de la dernière couche de MobileNetV2\n",
    "3. Définir le processus de chargement des images et l'application <br />\n",
    "   de leur featurisation à travers l'utilisation de pandas UDF\n",
    "3. Exécuter les actions d'extraction de features\n",
    "4. Enregistrer le résultat de nos actions\n",
    "5. Tester le bon fonctionnement en chargeant les données enregistrées\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386fe0bc",
   "metadata": {},
   "source": [
    "### 3.7.1 Chargement des données\n",
    "\n",
    "Les images sont chargées au format binaire, ce qui offre, <br />\n",
    "plus de souplesse dans la façon de prétraiter les images.\n",
    "\n",
    "Avant de charger les images, nous spécifions que nous voulons charger <br />\n",
    "uniquement les fichiers dont l'extension est **jpg**.\n",
    "\n",
    "Nous indiquons également de charger tous les objets possibles contenus <br />\n",
    "dans les sous-dossiers du dossier communiqué."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e68e53b9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-19T17:45:17.571604Z",
     "end_time": "2023-07-19T17:45:18.913680Z"
    }
   },
   "outputs": [],
   "source": [
    "images = spark.read.format(\"binaryFile\") \\\n",
    "  .option(\"pathGlobFilter\", \"*.jpg\") \\\n",
    "  .option(\"recursiveFileLookup\", \"true\") \\\n",
    "  .load(PATH_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645faeaf",
   "metadata": {},
   "source": [
    "<u>Affichage des 5 premières images contenant</u> :\n",
    " - le path de l'image\n",
    " - la date et heure de sa dernière modification\n",
    " - sa longueur\n",
    " - son contenu encodé en valeur hexadécimal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863981e5",
   "metadata": {},
   "source": [
    "<u>Je ne conserve que le **path** de l'image et j'ajoute <br />\n",
    "    une colonne contenant les **labels** de chaque image</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a08b0494",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-19T17:45:21.855463Z",
     "end_time": "2023-07-19T17:45:22.642311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- modificationTime: timestamp (nullable = true)\n",
      " |-- length: long (nullable = true)\n",
      " |-- content: binary (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n",
      "None\n",
      "+---------------------------------------------------------------------+-----+\n",
      "|path                                                                 |label|\n",
      "+---------------------------------------------------------------------+-----+\n",
      "|file:/home/maximorose/git_repositories/oc-ds-p08/data/imgs/r1_288.jpg|imgs |\n",
      "|file:/home/maximorose/git_repositories/oc-ds-p08/data/imgs/r1_300.jpg|imgs |\n",
      "|file:/home/maximorose/git_repositories/oc-ds-p08/data/imgs/r0_324.jpg|imgs |\n",
      "|file:/home/maximorose/git_repositories/oc-ds-p08/data/imgs/r0_36.jpg |imgs |\n",
      "|file:/home/maximorose/git_repositories/oc-ds-p08/data/imgs/r1_290.jpg|imgs |\n",
      "+---------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "images = images.withColumn('label', element_at(split(images['path'], '/'),-2))\n",
    "print(images.printSchema())\n",
    "print(images.select('path','label').show(5,False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d47705",
   "metadata": {},
   "source": [
    "### 3.7.2 Préparation du modèle\n",
    "\n",
    "Je vais utiliser la technique du **transfert learning** pour extraire les features des images.<br />\n",
    "J'ai choisi d'utiliser le modèle **MobileNetV2** pour sa rapidité d'exécution comparée <br />\n",
    "à d'autres modèles comme *VGG16* par exemple.\n",
    "\n",
    "Pour en savoir plus sur la conception et le fonctionnement de MobileNetV2, <br />\n",
    "je vous invite à lire [cet article](https://towardsdatascience.com/review-mobilenetv2-light-weight-model-image-classification-8febb490e61c).\n",
    "\n",
    "<u>Voici le schéma de son architecture globale</u> : \n",
    "\n",
    "![Architecture de MobileNetV2](img/mobilenetv2_architecture.png)\n",
    "\n",
    "Il existe une dernière couche qui sert à classer les images <br />\n",
    "selon 1000 catégories que nous ne voulons pas utiliser.<br />\n",
    "L'idée dans ce projet est de récupérer le **vecteur de caractéristiques <br />\n",
    "de dimensions (1,1,1280)** qui servira, plus tard, au travers d'un moteur <br />\n",
    "de classification à reconnaitre les différents fruits du jeu de données.\n",
    "\n",
    "Comme d'autres modèles similaires, **MobileNetV2**, lorsqu'on l'utilise <br />\n",
    "en incluant toutes ses couches, attend obligatoirement des images <br />\n",
    "de dimension (224,224,3). Nos images étant toutes de dimension (100,100,3), <br />\n",
    "nous devrons simplement les **redimensionner** avant de les confier au modèle.\n",
    "\n",
    "<u>Dans l'odre</u> :\n",
    " 1. Nous chargeons le modèle **MobileNetV2** avec les poids **précalculés** <br />\n",
    "    issus d'**imagenet** et en spécifiant le format de nos images en entrée\n",
    " 2. Nous créons un nouveau modèle avec:\n",
    "  - <u>en entrée</u> : l'entrée du modèle MobileNetV2\n",
    "  - <u>en sortie</u> : l'avant dernière couche du modèle MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cdd9bdf",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-19T17:45:24.923139Z",
     "end_time": "2023-07-19T17:45:25.810091Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 17:45:24.945982: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 17:45:24.948047: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model = MobileNetV2(weights='imagenet',\n",
    "                    include_top=True,\n",
    "                    input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99d6b68d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-19T17:45:27.213662Z",
     "end_time": "2023-07-19T17:45:27.222996Z"
    }
   },
   "outputs": [],
   "source": [
    "new_model = Model(inputs=model.input,\n",
    "                  outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b197379",
   "metadata": {},
   "source": [
    "Affichage du résumé de notre nouveau modèle où nous constatons <br />\n",
    "que <u>nous récupérons bien en sortie un vecteur de dimension (1, 1, 1280)</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8207725",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-19T17:45:30.535003Z",
     "end_time": "2023-07-19T17:45:30.718677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                    )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)              )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                          )                                ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]\n",
      "                                )                                [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']         \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 57, 57, 144)  0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 28, 28, 144)  1296       ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 28, 28, 144)  576        ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 28, 28, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 28, 28, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 28, 28, 32)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 28, 28, 32)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 29, 29, 192)  0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 14, 14, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 14, 14, 64)   0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 14, 14, 64)   0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 14, 14, 64)   0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 14, 14, 384)  24576       ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 14, 14, 384)  1536       ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 14, 14, 384)  0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 14, 14, 384)  3456       ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 14, 14, 384)  1536       ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0          ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 14, 14, 96)   36864       ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 14, 14, 96)   0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 14, 14, 96)   0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 1280)        0           ['out_relu[0][0]']               \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 2,223,872\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0adcf5",
   "metadata": {},
   "source": [
    "Tous les workers doivent pouvoir accéder au modèle ainsi qu'à ses poids. <br />\n",
    "Une bonne pratique consiste à charger le modèle sur le driver puis à diffuser <br />\n",
    "ensuite les poids aux différents workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cc53ff0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-19T17:45:33.626346Z",
     "end_time": "2023-07-19T17:45:33.714061Z"
    }
   },
   "outputs": [],
   "source": [
    "brodcast_weights = sc.broadcast(new_model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc0e34e",
   "metadata": {},
   "source": [
    "<u>Mettons cela sous forme de fonction</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fd51ba9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-19T17:45:35.560752Z",
     "end_time": "2023-07-19T17:45:35.567764Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    \"\"\"\n",
    "    Returns a MobileNetV2 model with top layer removed \n",
    "    and broadcasted pretrained weights.\n",
    "    \"\"\"\n",
    "    model = MobileNetV2(weights='imagenet',\n",
    "                        include_top=True,\n",
    "                        input_shape=(224, 224, 3))\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    new_model = Model(inputs=model.input,\n",
    "                  outputs=model.layers[-2].output)\n",
    "    new_model.set_weights(brodcast_weights.value)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5620876",
   "metadata": {},
   "source": [
    "### 3.7.3 Définition du processus de chargement des images et application <br/>de leur featurisation à travers l'utilisation de pandas UDF\n",
    "\n",
    "Ce notebook définit la logique par étapes, jusqu'à Pandas UDF.\n",
    "\n",
    "<u>L'empilement des appels est la suivante</u> :\n",
    "\n",
    "- Pandas UDF\n",
    "  - featuriser une série d'images pd.Series\n",
    "   - prétraiter une image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc4e5f69",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-19T17:45:36.835683Z",
     "end_time": "2023-07-19T17:45:36.893453Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximorose/anaconda3/envs/oc_ds_p8/lib/python3.10/site-packages/pyspark/sql/pandas/functions.py:389: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def preprocess(content):\n",
    "    \"\"\"\n",
    "    Preprocesses raw image bytes for prediction.\n",
    "    \"\"\"\n",
    "    img = Image.open(io.BytesIO(content)).resize([224, 224])\n",
    "    arr = img_to_array(img)\n",
    "    return preprocess_input(arr)\n",
    "\n",
    "def featurize_series(model, content_series):\n",
    "    \"\"\"\n",
    "    Featurize a pd.Series of raw images using the input model.\n",
    "    :return: a pd.Series of image features\n",
    "    \"\"\"\n",
    "    input = np.stack(content_series.map(preprocess))\n",
    "    preds = model.predict(input)\n",
    "    # For some layers, output features will be multi-dimensional tensors.\n",
    "    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n",
    "    output = [p.flatten() for p in preds]\n",
    "    return pd.Series(output)\n",
    "\n",
    "@pandas_udf('array<float>', PandasUDFType.SCALAR_ITER)\n",
    "def featurize_udf(content_series_iter):\n",
    "    \"\"\"\n",
    "    This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n",
    "    The decorator specifies that this returns a Spark DataFrame column of type ArrayType(FloatType).\n",
    "\n",
    "    :param content_series_iter: This argument is an iterator over batches of data, where each batch\n",
    "                              is a pandas Series of image data.\n",
    "    \"\"\"\n",
    "    # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n",
    "    # for multiple data batches.  This amortizes the overhead of loading big models.\n",
    "    model = model_fn()\n",
    "    for content_series in content_series_iter:\n",
    "        yield featurize_series(model, content_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdf2ef9",
   "metadata": {},
   "source": [
    "### 3.7.4 Exécution des actions d'extraction de features\n",
    "\n",
    "Les Pandas UDF, sur de grands enregistrements (par exemple, de très grandes images), <br />\n",
    "peuvent rencontrer des erreurs de type Out Of Memory (OOM).<br />\n",
    "Si vous rencontrez de telles erreurs dans la cellule ci-dessous, <br />\n",
    "essayez de réduire la taille du lot Arrow via 'maxRecordsPerBatch'\n",
    "\n",
    "Je n'utiliserai pas cette commande dans ce projet <br />\n",
    "et je laisse donc la commande en commentaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f30d28c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-19T17:45:39.074974Z",
     "end_time": "2023-07-19T17:45:39.095526Z"
    }
   },
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f8f95d",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant exécuter la featurisation sur l'ensemble de notre DataFrame Spark.\n",
    "\n",
    "<u>REMARQUE</u> : Cela peut prendre beaucoup de temps, tout dépend du volume de données à traiter. <br />\n",
    "\n",
    "Notre jeu de données de **Test** contient **22819 images**. Cependant, dans l'exécution en mode **local**, nous <u>traiterons un ensemble réduit de **330 images**</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69c1767c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-19T17:45:40.900415Z",
     "end_time": "2023-07-19T17:45:40.949159Z"
    }
   },
   "outputs": [],
   "source": [
    "features_df = images.repartition(20).select(col(\"path\"),\n",
    "                                            col(\"label\"),\n",
    "                                            featurize_udf(\"content\").alias(\"features\")\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5e83ec",
   "metadata": {},
   "source": [
    "<u>Rappel du PATH où seront inscrits les fichiers au format \"**parquet**\" <br />\n",
    "contenant nos résultats, à savoir, un DataFrame contenant 3 colonnes</u> :\n",
    " 1. Path des images\n",
    " 2. Label de l'image\n",
    " 3. Vecteur de caractéristiques de l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67fcdb0f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-19T17:45:44.165433Z",
     "end_time": "2023-07-19T17:45:44.178542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maximorose/git_repositories/oc-ds-p08/results\n"
     ]
    }
   ],
   "source": [
    "print(PATH_Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8901db3",
   "metadata": {},
   "source": [
    "<u>Enregistrement des données traitées au format \"**parquet**\"</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95d07466",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-19T17:45:51.394805Z",
     "end_time": "2023-07-19T17:46:12.706747Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 17:45:53.030694: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 17:45:53.031499: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 17:45:53.034192: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 17:45:53.034201: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 17:45:53.034314: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 17:45:53.046434: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 17:45:53.056846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 17:45:53.070491: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 17:45:56.269125: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 17:45:56.271066: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-07-19 17:45:56.274478: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 17:45:56.274477: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 17:45:56.276118: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-07-19 17:45:56.276703: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-07-19 17:45:56.279500: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 17:45:56.280861: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-07-19 17:45:56.284241: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 17:45:56.284553: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 17:45:56.285507: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-07-19 17:45:56.286428: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-07-19 17:45:56.339817: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 17:45:56.341509: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-07-19 17:45:56.352178: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 17:45:56.353779: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "23/07/19 17:46:02 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/07/19 17:46:02 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/07/19 17:46:03 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "features_df.write.mode(\"overwrite\").parquet(PATH_Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9506f21",
   "metadata": {},
   "source": [
    "## 3.8 Chargement des données enregistrées et validation du résultat\n",
    "\n",
    "<u>On charge les données fraichement enregistrées dans un **DataFrame Pandas**</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19243bf5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-19T17:46:46.157254Z",
     "end_time": "2023-07-19T17:46:46.228341Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet(PATH_Result, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f15070",
   "metadata": {},
   "source": [
    "<u>On affiche les 5 premières lignes du DataFrame</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a1bcdeb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-19T17:46:48.451118Z",
     "end_time": "2023-07-19T17:46:48.474753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                path label  \\\n0  file:/home/maximorose/git_repositories/oc-ds-p...  imgs   \n1  file:/home/maximorose/git_repositories/oc-ds-p...  imgs   \n2  file:/home/maximorose/git_repositories/oc-ds-p...  imgs   \n3  file:/home/maximorose/git_repositories/oc-ds-p...  imgs   \n4  file:/home/maximorose/git_repositories/oc-ds-p...  imgs   \n\n                                            features  \n0  [0.82194847, 0.00589833, 0.0, 0.0, 0.0, 0.0718...  \n1  [1.124969, 0.23398617, 0.002635654, 0.0, 0.0, ...  \n2  [1.2022287, 0.14649911, 0.0, 0.0, 0.0, 0.00143...  \n3  [1.247104, 0.2352836, 0.0, 0.0, 0.0, 0.0, 1.44...  \n4  [0.8724091, 0.21070303, 0.0, 0.0, 0.0, 0.00572...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>label</th>\n      <th>features</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>file:/home/maximorose/git_repositories/oc-ds-p...</td>\n      <td>imgs</td>\n      <td>[0.82194847, 0.00589833, 0.0, 0.0, 0.0, 0.0718...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>file:/home/maximorose/git_repositories/oc-ds-p...</td>\n      <td>imgs</td>\n      <td>[1.124969, 0.23398617, 0.002635654, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>file:/home/maximorose/git_repositories/oc-ds-p...</td>\n      <td>imgs</td>\n      <td>[1.2022287, 0.14649911, 0.0, 0.0, 0.0, 0.00143...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>file:/home/maximorose/git_repositories/oc-ds-p...</td>\n      <td>imgs</td>\n      <td>[1.247104, 0.2352836, 0.0, 0.0, 0.0, 0.0, 1.44...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>file:/home/maximorose/git_repositories/oc-ds-p...</td>\n      <td>imgs</td>\n      <td>[0.8724091, 0.21070303, 0.0, 0.0, 0.0, 0.00572...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2794fca",
   "metadata": {},
   "source": [
    "<u>On valide que la dimension du vecteur de caractéristiques des images est bien de dimension 1280</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bb933b9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-19T17:46:51.006261Z",
     "end_time": "2023-07-19T17:46:51.019032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(1280,)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,'features'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ACP PySpark sur features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "432.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
